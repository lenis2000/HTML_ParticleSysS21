Here we discuss the Markov property of TASEP.

#### Recall. Markov property

![[../img/Pasted image 20210203204422.png]]

Equivalently, the future and the past are independent conditioned on the state of the process at present.

#### Theorem 2.3.1

TASEP on $\mathbb{Z}$ started from any initial configuration is a Markov process on $\left\{ 0,1 \right\}^{\mathbb{Z}}$.

#### Proof 2.3.1

This is quite obvious, especially if we adopt the definition through independence of past and future. Indeed, if we fix the present, then the past and the future are determined by the states of the Poisson process on $\bigsqcup_{i\in \mathbb{Z}}\mathbb{R}$ corresponding to two disjoint sets. Therefore, we get independence directly from the properties of the Poisson process. $\qquad \square$

#### Remark 2.3.2

Is there another clock distribution, besides the exponential, such that TASEP constructed with these clocks is Markov? For example, what if the waiting time before the jump has uniform distribution on $[0,1]$?

It turns out that no. It is not hard to see that the Markov property of TASEP is equivalent to the memoryless property of the waiting time $\xi$:
$$
\mathsf{P}(\xi>a+b\mid \xi>a)=\mathsf{P}(\xi>b).
$$
This property, in its turn, is equivalent to the fact that the function $f(a)=\mathsf{P}(\xi>a)$ is multiplicative in $a$. Given the appropriate boundary conditions $f(0)=1$, $f(+\infty)=0$ coming from probability, we see that it must be $f(a)=e^{-\lambda a}$, which singles out the exponential distribution.
